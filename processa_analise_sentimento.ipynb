{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167a330b",
   "metadata": {},
   "source": [
    "# Análise das notícias sob a ótica ESG: geração da base com sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a2130b",
   "metadata": {},
   "source": [
    "- Autor: Daniel Saraiva Leite - 2023\n",
    "- Projeto Análise de sentimentos sobre notícias do tema ESG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c5d7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /Users/danielsaraivaleite/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/danielsaraivaleite/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danielsaraivaleite/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mp\n",
    "import seaborn as sns\n",
    "import datetime  as dt\n",
    "from noticias_timeline import plota_timeline\n",
    "from noticias_processamento_texto import *\n",
    "from noticias_graficos import *\n",
    "from analise_sentimento_modelo_gpt import *\n",
    "from classificador_esg import aplica_classificador_esg\n",
    "import pickle\n",
    "from cotacoes import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "lista_empresas = 'datasets/lista_empresas.xlsx'\n",
    "base_noticias = 'datasets/base_noticias.xlsx'\n",
    "base_noticias_saida = 'datasets/sentimento_base_noticias.xlsx'\n",
    "base_noticias_saida_short = 'datasets/sentimento_base_noticias_short.xlsx'\n",
    "caminho_cache='datasets/gpt_cache.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf1e355",
   "metadata": {},
   "source": [
    "## Lendo base de notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3e9497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(base_noticias)\n",
    "\n",
    "df['fonte'] = df['fonte'].apply(trata_nome_fontes)\n",
    "df['data_publicacao'] = df['data_publicacao'].dt.date\n",
    "df = df.sort_values(by=['empresa', 'data_publicacao'])\n",
    "df['titulo_par'] = df['titulo'].str.strip().apply(remove_acentos).str[:15]\n",
    "df = df.drop_duplicates(subset=['empresa', 'fonte', 'data_publicacao', 'titulo_par'], keep='first')\n",
    "del df['titulo_par']\n",
    "\n",
    "# ajustes\n",
    "df = ajusta_nomes_empresas_dataframe(df)\n",
    "\n",
    "# cria hash\n",
    "df['hash'] = df.apply(lambda row: criar_hash_noticia(row['texto_completo'], row['empresa'], titulo=row['titulo'], data=row['data_publicacao']), axis=1)\n",
    "\n",
    "# le lista empresas\n",
    "df_empresas = pd.read_excel(lista_empresas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8389c23",
   "metadata": {},
   "source": [
    "## Aplicação Classificador SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c32b37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utiliza o classificador por ML para determinar o assunto da noticia: E, S, G ou outros\n",
    "vect = pickle.load(open('models/svm_vetorizador.sav', 'rb'))\n",
    "model = pickle.load(open('models/svm_classificador.sav', 'rb'))\n",
    "\n",
    "if len(df.loc[ (pd.isnull(df['classificacao_ml']) &   (~pd.isnull(df['texto_completo']))), 'classificacao_ml']) >0:\n",
    "    df.loc[ (pd.isnull(df['classificacao_ml']) &   (~pd.isnull(df['texto_completo']))), 'classificacao_ml'] = aplica_classificador_esg(vect, model, \n",
    "                                                                                                              df.loc[ (pd.isnull(df['classificacao_ml']) &   (~pd.isnull(df['texto_completo'])))], \n",
    "                                                                                                              comparar_com_real=False, col_texto_origem='texto_completo', \n",
    "                                                                                                              col_texto_saida='texto_ajustado', col_classe_verdadeira='classificacao')       \n",
    "    \n",
    "# salva na base original para cache\n",
    "df.to_excel(base_noticias, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba7204d",
   "metadata": {},
   "source": [
    "## Aplicação do CHAT GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195249eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizadas 0 chamadas à API do GPT.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(base_noticias)\n",
    "\n",
    "# abre o cache\n",
    "df_cache = pd.read_excel(caminho_cache)\n",
    "dic_cache = df_cache.set_index('hash')['resposta'].to_dict()\n",
    "tam_inicial = len(dic_cache)\n",
    "\n",
    "\n",
    "try:\n",
    "    df['gpt_resposta_completa'] = df.apply(lambda row: classifica_sentimento_noticia_gpt(row['data_publicacao'], row['titulo'], row['texto_completo'], row['empresa'], dicionario_cache=dic_cache)  if (  (not pd.isnull(row['texto_completo'])) and row['classificacao_ml'] != 'Outros' and ( pd.isnull(row['gpt_resposta_completa'])) ) else row['gpt_resposta_completa'], axis=1)\n",
    "finally:                                                                    \n",
    "    #salva o cache do gpt\n",
    "    tam_final = len(dic_cache)\n",
    "    print('Realizadas ' + str(tam_final - tam_inicial) + ' chamadas à API do GPT.')\n",
    "    df_cache = pd.DataFrame({'hash': dic_cache.keys(),  'resposta': dic_cache.values()})\n",
    "    df_cache.to_excel(caminho_cache, index=False)\n",
    "\n",
    "# faz os filtros\n",
    "df.to_excel(base_noticias, index=False)\n",
    "df = df[~pd.isnull(df['texto_completo'])]\n",
    "df = df[df['classificacao_ml'] != 'Outros']  \n",
    "\n",
    "# tratando\n",
    "df = gera_colunas_gpt(df, coluna_resposta_gpt='gpt_resposta_completa')\n",
    "df = filtros_pos_gpt(df)\n",
    "df['polaridade'] = df['gpt_polaridade']  # substitui metodo anterior\n",
    "# resumos vazios\n",
    "df['gpt_resumo'] = df.apply(lambda row: row['titulo'] if pd.isnull(row['gpt_resumo']) else row['gpt_resumo'] , axis=1)\n",
    "\n",
    "df['gpt_lista_respostas'] = df['gpt_lista_respostas'].astype(str)  # para permitir remover duplicatas\n",
    "df = filtrar_noticias_pos_coleta_modelo_simplificado(df, df_empresas)\n",
    "\n",
    "df.to_excel(base_noticias_saida, index=False)\n",
    "\n",
    "# versao reduzida para o site\n",
    "df_short = df.loc[: , ['hash', 'titulo', 'data_publicacao', 'url', 'fonte', 'empresa', 'Nome',  'CNPJ', 'Razão social', 'Setor', 'Código',  'classificacao', 'gpt_resumo', 'polaridade']]\n",
    "df_short.to_excel(base_noticias_saida_short, index=False)\n",
    "\n",
    "print('Processamento concluído')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
