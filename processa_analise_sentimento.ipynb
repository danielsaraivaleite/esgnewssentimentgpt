{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167a330b",
   "metadata": {},
   "source": [
    "# Análise das notícias sob a ótica ESG: geração da base com sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a2130b",
   "metadata": {},
   "source": [
    "- Autor: Daniel Saraiva Leite - 2023\n",
    "- Projeto Análise de sentimentos sobre notícias do tema ESG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c5d7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielsaraivaleite/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/danielsaraivaleite/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/danielsaraivaleite/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /Users/danielsaraivaleite/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/danielsaraivaleite/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danielsaraivaleite/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime  as dt\n",
    "from noticias_processamento_texto import *\n",
    "from analise_sentimento_modelo_gpt import *\n",
    "from classificador_esg import aplica_classificador_esg\n",
    "import pickle\n",
    "from cotacoes import *\n",
    "from noticias_io import *\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf1e355",
   "metadata": {},
   "source": [
    "## Lendo base de notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3e9497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = le_base_noticias_bruta_para_df()\n",
    "\n",
    "df['fonte'] = df['fonte'].apply(trata_nome_fontes)\n",
    "df['data_publicacao'] = df['data_publicacao'].dt.date\n",
    "df = df.sort_values(by=['empresa', 'data_publicacao'])\n",
    "df['titulo_par'] = df['titulo'].str.strip().apply(remove_acentos).str[:15]\n",
    "df = df.drop_duplicates(subset=['empresa', 'fonte', 'data_publicacao', 'titulo_par'], keep='first')\n",
    "del df['titulo_par']\n",
    "\n",
    "# ajustes\n",
    "df = ajusta_nomes_empresas_dataframe(df)\n",
    "\n",
    "# cria hash\n",
    "df['hash'] = df.apply(lambda row: criar_hash_noticia(row['texto_completo'], row['empresa'], titulo=row['titulo'], data=row['data_publicacao']), axis=1)\n",
    "\n",
    "# le lista empresas\n",
    "df_empresas = le_lista_empresas_para_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8389c23",
   "metadata": {},
   "source": [
    "## Aplicação Classificador SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c32b37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E' 'G' 'Outros' 'S']\n",
      "[0.25568405 0.10168746 0.42157758 0.22105091]\n",
      "[1 3 0 2]\n",
      "0\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.10179023 0.42312524 0.45906843 0.0160161 ]\n",
      "[3 0 1 2]\n",
      "1\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.27576004 0.3082335  0.3498256  0.06618086]\n",
      "[3 0 1 2]\n",
      "1\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.38943484 0.0933052  0.4946246  0.02263536]\n",
      "[3 1 0 2]\n",
      "0\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.04449474 0.35379118 0.49750696 0.10420711]\n",
      "[0 3 1 2]\n",
      "1\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.21027229 0.11005053 0.42311063 0.25656655]\n",
      "[1 0 3 2]\n",
      "3\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.19922374 0.09217691 0.40054184 0.30805751]\n",
      "[1 0 3 2]\n",
      "3\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.14134733 0.34618481 0.4923382  0.02012966]\n",
      "[3 0 1 2]\n",
      "1\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.02024243 0.15432352 0.49330245 0.3321316 ]\n",
      "[0 1 3 2]\n",
      "3\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.30350382 0.09872146 0.3209707  0.27680402]\n",
      "[1 3 0 2]\n",
      "0\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.07448054 0.12188732 0.42537065 0.37826149]\n",
      "[0 1 3 2]\n",
      "3\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.14165166 0.29791607 0.43003751 0.13039476]\n",
      "[3 0 1 2]\n",
      "1\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.37056861 0.14010435 0.45499024 0.0343368 ]\n",
      "[3 1 0 2]\n",
      "0\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.01174174 0.30078367 0.4968345  0.19064009]\n",
      "[0 3 1 2]\n",
      "1\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.12741026 0.24609531 0.43687963 0.1896148 ]\n",
      "[0 3 1 2]\n",
      "1\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.18080879 0.19933917 0.36837965 0.25147239]\n",
      "[0 1 3 2]\n",
      "3\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.04449474 0.35379118 0.49750696 0.10420711]\n",
      "[0 3 1 2]\n",
      "1\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.04449474 0.35379118 0.49750696 0.10420711]\n",
      "[0 3 1 2]\n",
      "1\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.0924342  0.44169265 0.44225789 0.02361526]\n",
      "[3 0 1 2]\n",
      "1\n",
      "['E' 'G' 'Outros' 'S']\n",
      "[0.05457284 0.04578073 0.49058391 0.40906251]\n",
      "[1 0 3 2]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# utiliza o classificador por ML para determinar o assunto da noticia: E, S, G ou outros\n",
    "vect = pickle.load(open('models/svm_vetorizador.sav', 'rb'))\n",
    "model = pickle.load(open('models/svm_classificador.sav', 'rb'))\n",
    "\n",
    "if len(df.loc[ (pd.isnull(df['classificacao_ml']) &   (~pd.isnull(df['texto_completo']))), 'classificacao_ml']) >0:\n",
    "    df.loc[ (pd.isnull(df['classificacao_ml']) &   (~pd.isnull(df['texto_completo']))), 'classificacao_ml'] = aplica_classificador_esg(vect, model, \n",
    "                                                                                                              df.loc[ (pd.isnull(df['classificacao_ml']) &   (~pd.isnull(df['texto_completo'])))], \n",
    "                                                                                                              comparar_com_real=False, col_texto_origem='texto_completo', \n",
    "                                                                                                              col_texto_saida='texto_ajustado', col_classe_verdadeira='classificacao')       \n",
    "    \n",
    "# salva na base original para cache\n",
    "salva_base_noticias_bruta(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba7204d",
   "metadata": {},
   "source": [
    "## Aplicação do CHAT GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "195249eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizadas 388 chamadas à API do GPT.\n",
      "Processamento concluído\n"
     ]
    }
   ],
   "source": [
    "df = le_base_noticias_bruta_para_df()\n",
    "\n",
    "\n",
    "# abre o cache do chat gpt\n",
    "df_cache = le_cache_gpt_para_df()\n",
    "dic_cache = df_cache.set_index('hash')['resposta'].to_dict()\n",
    "tam_inicial = len(dic_cache)\n",
    "\n",
    "\n",
    "try:\n",
    "    df['gpt_resposta_completa'] = df.apply(lambda row: classifica_sentimento_noticia_gpt(row['data_publicacao'], row['titulo'], row['texto_completo'], row['empresa'], dicionario_cache=dic_cache)  \n",
    "                                                 if (  (not pd.isnull(row['texto_completo'])) and row['classificacao_ml'] != 'Outros' \n",
    "                                                         and ( pd.isnull(row['gpt_resposta_completa']))  \n",
    "                                                         and (  pd.isnull(row['noticia_selecionada']) or row['noticia_selecionada']==1   ) ) \n",
    "                                                         else row['gpt_resposta_completa'], axis=1)\n",
    "finally:                                                                    \n",
    "    #salva o cache do gpt\n",
    "    tam_final = len(dic_cache)\n",
    "    print('Realizadas ' + str(tam_final - tam_inicial) + ' chamadas à API do GPT.')\n",
    "    df_cache = pd.DataFrame({'hash': dic_cache.keys(),  'resposta': dic_cache.values()})\n",
    "    salva_cache_gpt(df_cache)\n",
    "\n",
    "# salva processamento na  base original\n",
    "salva_base_noticias_bruta(df)\n",
    "\n",
    "\n",
    "# faz os filtros\n",
    "df = df[  (  (pd.isnull(df['noticia_selecionada']))  |  (df['noticia_selecionada'] ==1)  )  ]\n",
    "df = df[~pd.isnull(df['texto_completo'])]\n",
    "df = df[df['classificacao_ml'] != 'Outros']  \n",
    "\n",
    "# tratando\n",
    "df = gera_colunas_gpt(df, coluna_resposta_gpt='gpt_resposta_completa')\n",
    "df = filtros_pos_gpt(df)\n",
    "df['polaridade'] = df['gpt_polaridade']  # substitui metodo anterior\n",
    "# resumos vazios\n",
    "df['gpt_resumo'] = df.apply(lambda row: row['titulo'] if pd.isnull(row['gpt_resumo']) else row['gpt_resumo'] , axis=1)\n",
    "\n",
    "df['gpt_lista_respostas'] = df['gpt_lista_respostas'].astype(str)  # para permitir remover duplicatas\n",
    "\n",
    "# filtro lexico aplicados apenas as  novas noticias\n",
    "df_filtrado = filtrar_noticias_pos_coleta_modelo_simplificado(df[pd.isnull(df['noticia_selecionada'])], df_empresas)\n",
    "\n",
    "# salva o resultado do filtro por eficiencia (salva na base sem sentimentos por eficiencia)\n",
    "# esse trecho permite que a rotina so seja aplicada a novas noticias futuramente, deixando proc. mais eficiente\n",
    "df_original = le_base_noticias_bruta_para_df()\n",
    "df_original['noticia_selecionada'] =  ( (df_original['noticia_selecionada']==1) |  df_original['hash'].isin(  df_filtrado['hash'].values  ) ).apply(lambda x: 1 if x else 0)\n",
    "salva_base_noticias_bruta(df_original)\n",
    "###\n",
    "\n",
    "\n",
    "# aplica o filtro na base ja com sentimentos\n",
    "df['noticia_selecionada'] =  ( (df['noticia_selecionada']==1) |  df['hash'].isin(  df_filtrado['hash'].values  ) ).apply(lambda x: 1 if x else 0)\n",
    "df = df[df['noticia_selecionada']==1] \n",
    "\n",
    "# retira duplicatas\n",
    "df = df.drop_duplicates(['hash'], keep='first')\n",
    "df = df.sort_values(by=['Nome', 'data_publicacao'])\n",
    "\n",
    "# salva a base de saida\n",
    "salva_base_noticias_processada(df)\n",
    "\n",
    "# versao reduzida para o site\n",
    "df_short = df.loc[: , ['hash', 'titulo', 'data_publicacao', 'url', 'fonte', 'empresa', 'Nome',  'CNPJ', 'Razão social', 'Setor', 'Código',  'classificacao', 'gpt_resumo', 'polaridade']]\n",
    "salva_base_noticias_compacta(df)\n",
    "\n",
    "print('Processamento concluído')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6326228e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd6697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
