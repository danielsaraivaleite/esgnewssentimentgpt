{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03cde1f2",
   "metadata": {},
   "source": [
    "# Construção da base de notícias ESG a partir da captura do Google RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778bd9fa",
   "metadata": {},
   "source": [
    "- Autor: Daniel Saraiva Leite - 2023\n",
    "- Projeto Análise de sentimentos sobre notícias do tema ESG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5cac40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from noticias_google_buscador import busca_noticias_google_news\n",
    "from noticias_google_buscador_esg import *\n",
    "import numpy as np\n",
    "from noticias_io import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1ebec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-03-10 22:36:48.627915 Buscando empresa irb brasil re\n",
      "...... buscando no google irb brasil re\n",
      "\n",
      "2024-03-10 22:36:56.324426 Buscando apelido irb resseguros da empresa irb brasil re\n",
      "...... buscando no google irb resseguros\n",
      "\n",
      "2024-03-10 22:37:28.717891 Buscando apelido IRBR3 da empresa irb brasil re\n",
      "...... buscando no google IRBR3\n",
      "2024-03-10 22:38:01.002439 ... noticias encontradas: 521\n",
      "2024-03-10 22:38:01.013828 ... noticias novas: 444\n"
     ]
    }
   ],
   "source": [
    "df_atual = le_base_noticias_bruta_para_df()\n",
    "df_empresas = le_lista_empresas_para_df()\n",
    "\n",
    "hash_noticias_ja_existentes = list(df_atual['hash'])\n",
    "\n",
    "# processa empresas\n",
    "for i, row in df_empresas[df_empresas['buscar'].str.upper() == 'SIM'].iterrows():\n",
    "    \n",
    "    empresa = row['empresa']\n",
    "    \n",
    "    aplicar_filtros= ( (not pd.isnull(row['aplicar_filtros_relevancia'])) and   row['aplicar_filtros_relevancia'].upper() == 'SIM')\n",
    "    inclui_apenas_nome_empresa = ( (not pd.isnull(row['tipo_busca_exaustiva'])) and    row['tipo_busca_exaustiva'].upper() == 'SIM')\n",
    "    buscar_apelidos= ( (not pd.isnull(row['buscar_apelidos'])) and   row['buscar_apelidos'].upper() == 'SIM')\n",
    "    \n",
    "    \n",
    "    atualiza = (  (not pd.isnull(row['tipo_busca_atualizacao'])) and    row['tipo_busca_atualizacao'].upper() == 'SIM' and (not pd.isnull(row['ultima_data_publicacao'])))\n",
    "    ultima_data = row['ultima_data_publicacao'].date()\n",
    "    \n",
    "    print('\\n' +  str(dt.datetime.now())  + ' Buscando empresa ' + empresa)\n",
    "    dfEmpresasListadas = df_empresas\n",
    "    \n",
    "    df1 = busca_noticias_google_esg(empresa, atualiza=atualiza, ultima_data = ultima_data, inclui_apenas_nome_empresa = inclui_apenas_nome_empresa)\n",
    "    # verifica se faz a busca por apelidos tambem (ex banco do brasil > BB)\n",
    "    if buscar_apelidos and (not pd.isnull(row['apelidos'])):\n",
    "        for apelido in row['apelidos'].split(','):\n",
    "            print('\\n' +  str(dt.datetime.now())  + ' Buscando apelido ' + apelido + \" da empresa \" + empresa)\n",
    "            df1_apelido = busca_noticias_google_esg(apelido, atualiza=atualiza, ultima_data = ultima_data, inclui_apenas_nome_empresa = inclui_apenas_nome_empresa)\n",
    "\n",
    "            if df1_apelido is not None and len(df1_apelido) >0:\n",
    "                if df1 is not None and len(df1) > 0:\n",
    "                    df1 = pd.concat([df1,df1_apelido]).drop_duplicates(ignore_index=True)\n",
    "                else:\n",
    "                    df1 = df1_apelido\n",
    "        \n",
    "    if len(df1) >0:\n",
    "        # ajustes\n",
    "        #df1['data_publicacao'] = df1['data_publicacao'].dt.date\n",
    "        df1['empresa'] = empresa # mantem padrao do nome caso tenham apelidos\n",
    "        df1 = ajusta_nomes_empresas_dataframe(df1)\n",
    "\n",
    "        # cria hash\n",
    "        df1['hash'] = df1.apply(lambda row: criar_hash_noticia(texto=row['titulo'], empresa=row['empresa'], titulo=row['titulo'], data=row['data_publicacao']), axis=1)\n",
    "        print(str(dt.datetime.now())  + ' ... noticias encontradas: ' + str(len(df1)))\n",
    "    \n",
    "    if len(df1) >0:\n",
    "        df1 = df1[~df1['hash'].isin(hash_noticias_ja_existentes)]\n",
    "        print(str(dt.datetime.now())  + ' ... noticias novas: ' + str(len(df1)))\n",
    "    \n",
    "    if len(df1) > 0:\n",
    "        df2 = recupera_noticias_completas(df1)\n",
    "        #print(df1)\n",
    "        print(str(dt.datetime.now())  + ' ... textos buscados: ' + str(len(df2)))\n",
    "            \n",
    "        if aplicar_filtros:\n",
    "            df3 = filtra_noticias_nao_relacionadas(df2, empresa)\n",
    "            if len(df3) >0:\n",
    "                df4 = filtra_citacao_relevante(df3, empresa, dfEmpresasListadas )\n",
    "                print(str(dt.datetime.now())  + ' ... novas noticias após filtro citaçoes: ' + str(len(df4)))\n",
    "                \n",
    "        else:\n",
    "            df4 = df2\n",
    "        \n",
    "        if len(df4) >0:\n",
    "            df5 = classifica_textos_coletados(df4)\n",
    "            df6 = df5\n",
    "            print(str(dt.datetime.now())  + ' ... novas noticias após filtros: ' + str(len(df6)))\n",
    "            df_atual = le_base_noticias_bruta_para_df()\n",
    "            df = pd.concat([df_atual,df6]).drop_duplicates(ignore_index=True)\n",
    "            df = df.drop_duplicates(['titulo','empresa','fonte', 'texto_completo'], keep='first')\n",
    "            salva_base_noticias_bruta(df)\n",
    "\n",
    "\n",
    "# complementando os dados\n",
    "# atualiza nome, cnpj, setor\n",
    "df_noticias = le_base_noticias_bruta_para_df()\n",
    "df_empresas = le_lista_empresas_para_df()\n",
    "df_noticias['Nome'] = df_noticias['empresa'].map(df_empresas.set_index('empresa')['Nome'])\n",
    "df_noticias['CNPJ'] = df_noticias['empresa'].map(df_empresas.set_index('empresa')['CNPJ'])\n",
    "df_noticias['Razão social'] = df_noticias['empresa'].map(df_empresas.set_index('empresa')['RAZÃO SOCIAL'])\n",
    "df_noticias['Código'] = df_noticias['empresa'].map(df_empresas.set_index('empresa')['Código'])\n",
    "df_noticias['Setor'] = df_noticias['empresa'].map(df_empresas.set_index('empresa')['SETOR'])\n",
    "salva_base_noticias_bruta(df_noticias)\n",
    "\n",
    "# atualiza ultima data de captura\n",
    "df_empresas['ultima_data_publicacao'] = df_empresas['empresa'].map(df_noticias[['empresa', 'data_publicacao']].groupby('empresa').max()['data_publicacao'] )\n",
    "salva_lista_empresas(df_empresas)\n",
    "\n",
    "print('\\nCaptura concluída')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
