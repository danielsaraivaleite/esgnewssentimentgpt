{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03cde1f2",
   "metadata": {},
   "source": [
    "# Construção da base de notícias ESG a partir da captura do Google RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778bd9fa",
   "metadata": {},
   "source": [
    "- Autor: Daniel Saraiva Leite - 2023\n",
    "- Projeto Análise de sentimentos sobre notícias do tema ESG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5cac40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from noticias_google_buscador import busca_noticias_google_news\n",
    "from noticias_google_buscador_esg import *\n",
    "import numpy as np\n",
    "from noticias_io import *\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1f1ebec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-03-05 21:34:44.405605 Buscando empresa camargo correa\n",
      "...... buscando no google camargo+correa\n",
      "2024-03-05 21:35:26.084775 ... noticias encontradas: 13\n",
      "2024-03-05 21:35:26.093047 ... noticias novas: 13\n",
      "2024-03-05 21:35:53.799880 ... textos buscados: 13\n",
      "2024-03-05 21:35:55.955110 ... novas noticias após filtros: 13\n",
      "\n",
      "2024-03-05 21:35:58.266362 Buscando empresa cemig\n",
      "...... buscando no google cemig\n",
      "2024-03-05 21:36:01.516714 ... noticias encontradas: 29\n",
      "2024-03-05 21:36:01.524646 ... noticias novas: 28\n",
      "2024-03-05 21:37:09.127174 ... textos buscados: 25\n",
      "2024-03-05 21:37:12.313484 ... novas noticias após filtros: 25\n",
      "\n",
      "2024-03-05 21:37:13.897398 Buscando empresa credz\n",
      "...... buscando no google credz\n",
      "2024-03-05 21:37:55.255489 ... noticias encontradas: 5\n",
      "2024-03-05 21:37:55.266139 ... noticias novas: 5\n",
      "2024-03-05 21:38:10.166687 ... textos buscados: 5\n",
      "2024-03-05 21:38:10.832615 ... novas noticias após filtros: 5\n",
      "\n",
      "2024-03-05 21:38:12.374578 Buscando empresa eletrobras\n",
      "...... buscando no google eletrobras\n",
      "2024-03-05 21:38:15.846213 ... noticias encontradas: 70\n",
      "2024-03-05 21:38:15.853972 ... noticias novas: 69\n",
      "2024-03-05 21:41:36.987262 ... textos buscados: 63\n",
      "2024-03-05 21:41:45.074827 ... novas noticias após filtros: 63\n",
      "\n",
      "2024-03-05 21:41:46.654370 Buscando empresa havan\n",
      "...... buscando no google havan\n",
      "2024-03-05 21:42:26.490709 ... noticias encontradas: 19\n",
      "2024-03-05 21:42:26.500033 ... noticias novas: 19\n",
      "2024-03-05 21:43:07.136034 ... textos buscados: 19\n",
      "2024-03-05 21:43:09.355090 ... novas noticias após filtros: 19\n",
      "\n",
      "2024-03-05 21:43:10.791618 Buscando empresa jbs\n",
      "...... buscando no google jbs\n",
      "2024-03-05 21:43:14.623953 ... noticias encontradas: 52\n",
      "2024-03-05 21:43:14.631511 ... noticias novas: 52\n",
      "2024-03-05 21:44:43.110477 ... textos buscados: 50\n",
      "2024-03-05 21:44:49.187139 ... novas noticias após filtros: 50\n",
      "\n",
      "2024-03-05 21:44:50.631035 Buscando empresa oi\n",
      "...... buscando no google oi\n",
      "2024-03-05 21:45:29.007655 ... noticias encontradas: 108\n",
      "2024-03-05 21:45:29.017109 ... noticias novas: 108\n",
      "2024-03-05 21:49:28.501226 ... textos buscados: 107\n",
      "2024-03-05 21:49:41.908255 ... novas noticias após filtros: 107\n",
      "\n",
      "2024-03-05 21:49:43.586361 Buscando empresa unigel\n",
      "...... buscando no google unigel\n",
      "2024-03-05 21:50:21.553526 ... noticias encontradas: 16\n",
      "2024-03-05 21:50:21.559563 ... noticias novas: 16\n",
      "2024-03-05 21:51:12.474807 ... textos buscados: 15\n",
      "2024-03-05 21:51:14.296389 ... novas noticias após filtros: 15\n",
      "\n",
      "2024-03-05 21:51:15.815186 Buscando empresa valid\n",
      "...... buscando no google valid\n",
      "2024-03-05 21:51:56.609525 ... noticias encontradas: 189\n",
      "2024-03-05 21:51:56.617720 ... noticias novas: 189\n",
      "2024-03-05 22:00:43.165356 ... textos buscados: 147\n",
      "2024-03-05 22:01:06.703495 ... novas noticias após filtros: 147\n",
      "\n",
      "Captura concluída\n"
     ]
    }
   ],
   "source": [
    "df_atual = le_base_noticias_bruta_para_df()\n",
    "df_empresas = le_lista_empresas_para_df()\n",
    "\n",
    "hash_noticias_ja_existentes = list(df_atual['hash'])\n",
    "\n",
    "# processa empresas\n",
    "for i, row in df_empresas[df_empresas['buscar'].str.upper() == 'SIM'].iterrows():\n",
    "    \n",
    "    empresa = row['empresa']\n",
    "    \n",
    "    aplicar_filtros= ( (not pd.isnull(row['aplicar_filtros_relevancia'])) and   row['aplicar_filtros_relevancia'].upper() == 'SIM')\n",
    "    inclui_apenas_nome_empresa = ( (not pd.isnull(row['tipo_busca_exaustiva'])) and    row['tipo_busca_exaustiva'].upper() == 'SIM')\n",
    "    \n",
    "    atualiza = (  (not pd.isnull(row['tipo_busca_atualizacao'])) and    row['tipo_busca_atualizacao'].upper() == 'SIM' and (not pd.isnull(row['ultima_data_publicacao'])))\n",
    "    ultima_data = row['ultima_data_publicacao'].date()\n",
    "    \n",
    "    print('\\n' +  str(dt.datetime.now())  + ' Buscando empresa ' + empresa)\n",
    "    dfEmpresasListadas = df_empresas\n",
    "    \n",
    "    df1 = busca_noticias_google_esg(empresa, atualiza=atualiza, ultima_data = ultima_data, inclui_apenas_nome_empresa = inclui_apenas_nome_empresa)\n",
    "    \n",
    "    if len(df1) >0:\n",
    "        # ajustes\n",
    "        #df1['data_publicacao'] = df1['data_publicacao'].dt.date\n",
    "        df1 = ajusta_nomes_empresas_dataframe(df1)\n",
    "\n",
    "        # cria hash\n",
    "        df1['hash'] = df1.apply(lambda row: criar_hash_noticia(texto=row['titulo'], empresa=row['empresa'], titulo=row['titulo'], data=row['data_publicacao']), axis=1)\n",
    "        print(str(dt.datetime.now())  + ' ... noticias encontradas: ' + str(len(df1)))\n",
    "    \n",
    "    if len(df1) >0:\n",
    "        df1 = df1[~df1['hash'].isin(hash_noticias_ja_existentes)]\n",
    "        print(str(dt.datetime.now())  + ' ... noticias novas: ' + str(len(df1)))\n",
    "    \n",
    "    if len(df1) > 0:\n",
    "        df2 = recupera_noticias_completas(df1)\n",
    "        #print(df1)\n",
    "        print(str(dt.datetime.now())  + ' ... textos buscados: ' + str(len(df2)))\n",
    "            \n",
    "        if aplicar_filtros:\n",
    "            df3 = filtra_noticias_nao_relacionadas(df2, empresa)\n",
    "            if len(df3) >0:\n",
    "                df4 = filtra_citacao_relevante(df3, empresa, dfEmpresasListadas )\n",
    "                print(str(dt.datetime.now())  + ' ... novas noticias após filtro citaçoes: ' + str(len(df4)))\n",
    "                \n",
    "        else:\n",
    "            df4 = df2\n",
    "        \n",
    "        if len(df4) >0:\n",
    "            df5 = classifica_textos_coletados(df4)\n",
    "            df6 = df5\n",
    "            print(str(dt.datetime.now())  + ' ... novas noticias após filtros: ' + str(len(df6)))\n",
    "            df_atual = le_base_noticias_bruta_para_df()\n",
    "            df = pd.concat([df_atual,df6]).drop_duplicates(ignore_index=True)\n",
    "            df = df.drop_duplicates(['titulo','empresa','fonte', 'texto_completo'], keep='first')\n",
    "            salva_base_noticias_bruta(df)\n",
    "\n",
    "\n",
    "# complementando os dados\n",
    "# atualiza nome, cnpj, setor\n",
    "df_noticias = le_base_noticias_bruta_para_df()\n",
    "df_empresas = le_lista_empresas_para_df()\n",
    "df_noticias['Nome'] = df_noticias['empresa'].map(df_empresas.set_index('empresa')['Nome'])\n",
    "df_noticias['CNPJ'] = df_noticias['empresa'].map(df_empresas.set_index('empresa')['CNPJ'])\n",
    "df_noticias['Razão social'] = df_noticias['empresa'].map(df_empresas.set_index('empresa')['RAZÃO SOCIAL'])\n",
    "df_noticias['Código'] = df_noticias['empresa'].map(df_empresas.set_index('empresa')['Código'])\n",
    "df_noticias['Setor'] = df_noticias['empresa'].map(df_empresas.set_index('empresa')['SETOR'])\n",
    "salva_base_noticias_bruta(df_noticias)\n",
    "\n",
    "# atualiza ultima data de captura\n",
    "df_empresas['ultima_data_publicacao'] = df_empresas['empresa'].map(df_noticias[['empresa', 'data_publicacao']].groupby('empresa').max()['data_publicacao'] )\n",
    "salva_lista_empresas(df_empresas)\n",
    "\n",
    "print('\\nCaptura concluída')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c7599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704bd130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c90c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
