{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03cde1f2",
   "metadata": {},
   "source": [
    "# Construção da base de notícias ESG a partir da captura do Google RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778bd9fa",
   "metadata": {},
   "source": [
    "- Autor: Daniel Saraiva Leite - 2023\n",
    "- Projeto Análise de sentimentos sobre notícias do tema ESG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5cac40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielsaraivaleite/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/danielsaraivaleite/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/danielsaraivaleite/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /Users/danielsaraivaleite/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/danielsaraivaleite/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danielsaraivaleite/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from noticias_google_buscador import busca_noticias_google_news\n",
    "from noticias_google_buscador_esg import *\n",
    "import numpy as np\n",
    "from noticias_io import *\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f1ebec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-03-03 22:06:18.398006 Buscando empresa slc agricola\n",
      "...... buscando no google slc+agricola\n",
      "2024-03-03 22:06:57.576284 ... noticias encontradas: 37\n",
      "2024-03-03 22:06:57.589154 ... noticias novas: 22\n",
      "2024-03-03 22:07:40.296447 ... textos buscados: 18\n",
      "2024-03-03 22:07:42.931477 ... novas noticias após filtros: 18\n",
      "\n",
      "2024-03-03 22:07:44.264360 Buscando empresa taurus\n",
      "...... buscando no google taurus\n",
      "2024-03-03 22:08:23.801470 ... noticias encontradas: 44\n",
      "2024-03-03 22:08:23.808762 ... noticias novas: 44\n",
      "2024-03-03 22:09:32.609276 ... textos buscados: 44\n",
      "2024-03-03 22:09:38.407759 ... novas noticias após filtros: 44\n",
      "\n",
      "2024-03-03 22:09:39.717227 Buscando empresa terra santa propriedades agricolas\n",
      "...... buscando no google terra+santa+propriedades+agricolas\n",
      "2024-03-03 22:10:20.019581 ... noticias encontradas: 12\n",
      "2024-03-03 22:10:20.028467 ... noticias novas: 11\n",
      "2024-03-03 22:10:39.251429 ... textos buscados: 11\n",
      "2024-03-03 22:10:40.693140 ... novas noticias após filtros: 11\n",
      "\n",
      "2024-03-03 22:10:41.996955 Buscando empresa ultrapar\n",
      "...... buscando no google ultrapar\n",
      "2024-03-03 22:11:23.202561 ... noticias encontradas: 45\n",
      "2024-03-03 22:11:23.210914 ... noticias novas: 45\n",
      "2024-03-03 22:13:55.012189 ... textos buscados: 37\n",
      "2024-03-03 22:14:00.396968 ... novas noticias após filtros: 37\n",
      "\n",
      "2024-03-03 22:14:01.793114 Buscando empresa unilever\n",
      "...... buscando no google unilever\n",
      "2024-03-03 22:14:47.710703 ... noticias encontradas: 163\n",
      "2024-03-03 22:14:47.717099 ... noticias novas: 86\n",
      "2024-03-03 22:18:19.626391 ... textos buscados: 52\n",
      "2024-03-03 22:18:26.924297 ... novas noticias após filtros: 52\n",
      "\n",
      "2024-03-03 22:18:28.255509 Buscando empresa usiminas\n",
      "...... buscando no google usiminas\n",
      "2024-03-03 22:19:11.414612 ... noticias encontradas: 179\n",
      "2024-03-03 22:19:11.420169 ... noticias novas: 158\n",
      "2024-03-03 22:27:37.353740 ... textos buscados: 136\n",
      "2024-03-03 22:27:55.597384 ... novas noticias após filtros: 136\n",
      "\n",
      "2024-03-03 22:27:57.211659 Buscando empresa vale\n",
      "...... buscando no google vale\n",
      "2024-03-03 22:28:44.147874 ... noticias encontradas: 224\n",
      "2024-03-03 22:28:44.156762 ... noticias novas: 148\n",
      "2024-03-03 22:34:54.398889 ... textos buscados: 140\n",
      "2024-03-03 22:35:15.366407 ... novas noticias após filtros: 140\n",
      "\n",
      "2024-03-03 22:35:16.888616 Buscando empresa via\n",
      "...... buscando no google via\n",
      "2024-03-03 22:36:04.048229 ... noticias encontradas: 115\n",
      "2024-03-03 22:36:04.057335 ... noticias novas: 100\n",
      "2024-03-03 22:40:10.168621 ... textos buscados: 89\n",
      "2024-03-03 22:40:23.038177 ... novas noticias após filtros: 89\n",
      "\n",
      "2024-03-03 22:40:24.533983 Buscando empresa vibra energia\n",
      "...... buscando no google vibra+energia\n",
      "2024-03-03 22:40:59.274531 ... noticias encontradas: 94\n",
      "2024-03-03 22:40:59.284016 ... noticias novas: 81\n",
      "2024-03-03 22:44:00.145234 ... textos buscados: 68\n",
      "2024-03-03 22:44:08.635860 ... novas noticias após filtros: 68\n",
      "\n",
      "2024-03-03 22:44:10.050763 Buscando empresa vivo\n",
      "...... buscando no google vivo\n",
      "2024-03-03 22:44:47.545255 ... noticias encontradas: 314\n",
      "2024-03-03 22:44:47.550516 ... noticias novas: 231\n",
      "2024-03-03 22:51:44.102932 ... textos buscados: 227\n",
      "2024-03-03 22:52:13.893868 ... novas noticias após filtros: 227\n",
      "\n",
      "2024-03-03 22:52:15.492652 Buscando empresa weg\n",
      "...... buscando no google weg\n",
      "2024-03-03 22:52:58.153491 ... noticias encontradas: 47\n",
      "2024-03-03 22:52:58.164187 ... noticias novas: 27\n",
      "2024-03-03 22:54:02.604709 ... textos buscados: 20\n",
      "2024-03-03 22:54:05.138512 ... novas noticias após filtros: 20\n",
      "\n",
      "Captura concluída\n"
     ]
    }
   ],
   "source": [
    "df_atual = le_base_noticias_bruta_para_df()\n",
    "df_empresas = le_lista_empresas_para_df()\n",
    "\n",
    "hash_noticias_ja_existentes = list(df_atual['hash'])\n",
    "\n",
    "# processa empresas\n",
    "for i, row in df_empresas[df_empresas['buscar'].str.upper() == 'SIM'].iterrows():\n",
    "    \n",
    "    empresa = row['empresa']\n",
    "    \n",
    "    aplicar_filtros= ( (not pd.isnull(row['aplicar_filtros_relevancia'])) and   row['aplicar_filtros_relevancia'].upper() == 'SIM')\n",
    "    inclui_apenas_nome_empresa = ( (not pd.isnull(row['tipo_busca_exaustiva'])) and    row['tipo_busca_exaustiva'].upper() == 'SIM')\n",
    "    \n",
    "    atualiza = (  (not pd.isnull(row['tipo_busca_atualizacao'])) and    row['tipo_busca_atualizacao'].upper() == 'SIM' and (not pd.isnull(row['ultima_data_publicacao'])))\n",
    "    ultima_data = row['ultima_data_publicacao'].date()\n",
    "    \n",
    "    print('\\n' +  str(dt.datetime.now())  + ' Buscando empresa ' + empresa)\n",
    "    dfEmpresasListadas = df_empresas\n",
    "    \n",
    "    df1 = busca_noticias_google_esg(empresa, atualiza=atualiza, ultima_data = ultima_data, inclui_apenas_nome_empresa = inclui_apenas_nome_empresa)\n",
    "    \n",
    "    if len(df1) >0:\n",
    "        # ajustes\n",
    "        #df1['data_publicacao'] = df1['data_publicacao'].dt.date\n",
    "        df1 = ajusta_nomes_empresas_dataframe(df1)\n",
    "\n",
    "        # cria hash\n",
    "        df1['hash'] = df1.apply(lambda row: criar_hash_noticia(texto=row['titulo'], empresa=row['empresa'], titulo=row['titulo'], data=row['data_publicacao']), axis=1)\n",
    "        print(str(dt.datetime.now())  + ' ... noticias encontradas: ' + str(len(df1)))\n",
    "    \n",
    "    if len(df1) >0:\n",
    "        df1 = df1[~df1['hash'].isin(hash_noticias_ja_existentes)]\n",
    "        print(str(dt.datetime.now())  + ' ... noticias novas: ' + str(len(df1)))\n",
    "    \n",
    "    if len(df1) > 0:\n",
    "        df2 = recupera_noticias_completas(df1)\n",
    "        #print(df1)\n",
    "        print(str(dt.datetime.now())  + ' ... textos buscados: ' + str(len(df2)))\n",
    "            \n",
    "        if aplicar_filtros:\n",
    "            df3 = filtra_noticias_nao_relacionadas(df2, empresa)\n",
    "            if len(df3) >0:\n",
    "                df4 = filtra_citacao_relevante(df3, empresa, dfEmpresasListadas )\n",
    "                print(str(dt.datetime.now())  + ' ... novas noticias após filtro citaçoes: ' + str(len(df4)))\n",
    "                \n",
    "        else:\n",
    "            df4 = df2\n",
    "        \n",
    "        if len(df4) >0:\n",
    "            df5 = classifica_textos_coletados(df4)\n",
    "            df6 = df5\n",
    "            print(str(dt.datetime.now())  + ' ... novas noticias após filtros: ' + str(len(df6)))\n",
    "            df_atual = le_base_noticias_bruta_para_df()\n",
    "            df = pd.concat([df_atual,df6]).drop_duplicates(ignore_index=True)\n",
    "            df = df.drop_duplicates(['titulo','empresa','fonte', 'texto_completo'], keep='first')\n",
    "            salva_base_noticias_bruta(df)\n",
    "\n",
    "\n",
    "# complementando os dados\n",
    "# atualiza nome, cnpj, setor\n",
    "df_noticias = le_base_noticias_bruta_para_df()\n",
    "df_empresas = le_lista_empresas_para_df()\n",
    "df_noticias['Nome'] = df_noticias['empresa'].map(df_empresas.set_index('empresa')['Nome'])\n",
    "df_noticias['CNPJ'] = df_noticias['empresa'].map(df_empresas.set_index('empresa')['CNPJ'])\n",
    "df_noticias['Razão social'] = df_noticias['empresa'].map(df_empresas.set_index('empresa')['RAZÃO SOCIAL'])\n",
    "df_noticias['Código'] = df_noticias['empresa'].map(df_empresas.set_index('empresa')['Código'])\n",
    "df_noticias['Setor'] = df_noticias['empresa'].map(df_empresas.set_index('empresa')['SETOR'])\n",
    "salva_base_noticias_bruta(df_noticias)\n",
    "\n",
    "# atualiza ultima data de captura\n",
    "df_empresas['ultima_data_publicacao'] = df_empresas['empresa'].map(df_noticias[['empresa', 'data_publicacao']].groupby('empresa').max()['data_publicacao'] )\n",
    "salva_lista_empresas(df_empresas)\n",
    "\n",
    "print('\\nCaptura concluída')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c7599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704bd130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c90c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
