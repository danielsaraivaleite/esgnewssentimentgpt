{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03cde1f2",
   "metadata": {},
   "source": [
    "# Construção da base de notícias ESG a partir da captura do Google RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778bd9fa",
   "metadata": {},
   "source": [
    "- Autor: Daniel Saraiva Leite - 2023\n",
    "- Projeto Análise de sentimentos sobre notícias do tema ESG\n",
    "- Trabalho de conclusão de curso - MBA Digital Business USP Esalq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5cac40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /Users/danielsaraivaleite/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/danielsaraivaleite/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danielsaraivaleite/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import unidecode\n",
    "import datetime as dt\n",
    "from noticias_google_buscador import busca_noticias_google_news\n",
    "from noticias_processamento_texto import *\n",
    "from noticias_google_buscador_esg import *\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "arquivo_termos_esg = 'datasets/palavras_chave_esg.xlsx'\n",
    "base_noticias = 'datasets/base_noticias.xlsx'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1ebec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-02-22 22:17:36.264210 Buscando empresa brasil biofuels\n",
      "...... buscando no google brasil+biofuels\n",
      "2024-02-22 22:18:38.283955 ... noticias encontradas: 316\n",
      "2024-02-22 22:18:38.286377 ... noticias novas: 256\n"
     ]
    }
   ],
   "source": [
    "aplicar_filtros=False\n",
    "inclui_apenas_nome_empresa = True\n",
    "\n",
    "df_atual = pd.read_excel(base_noticias)\n",
    "\n",
    "hash_noticias_ja_existentes = list(df_atual['hash'])\n",
    "\n",
    "# processa uma empresa especificada\n",
    "for empresa in [  'brasil biofuels']:\n",
    "    print('\\n' +  str(dt.datetime.now())  + ' Buscando empresa ' + empresa)\n",
    "    dfEmpresasListadas = recupera_lista_empresas_B3()\n",
    "    df1 = busca_noticias_google_esg(empresa, inclui_apenas_nome_empresa = True)\n",
    "    \n",
    "    if len(df1) >0:\n",
    "        # ajustes\n",
    "        df1['data_publicacao'] = df1['data_publicacao'].dt.date\n",
    "        df1 = ajusta_nomes_empresas_dataframe(df1)\n",
    "\n",
    "        # cria hash\n",
    "        df1['hash'] = df1.apply(lambda row: criar_hash_noticia(texto=row['titulo'], empresa=row['empresa'], titulo=row['titulo'], data=row['data_publicacao']), axis=1)\n",
    "        print(str(dt.datetime.now())  + ' ... noticias encontradas: ' + str(len(df1)))\n",
    "    \n",
    "    if len(df1) >0:\n",
    "        df1 = df1[~df1['hash'].isin(hash_noticias_ja_existentes)]\n",
    "        print(str(dt.datetime.now())  + ' ... noticias novas: ' + str(len(df1)))\n",
    "    \n",
    "    if len(df1) > 0:\n",
    "        df2 = recupera_noticias_completas(df1)\n",
    "        print(df1)\n",
    "        print(str(dt.datetime.now())  + ' ... textos buscados: ' + str(len(df2)))\n",
    "            \n",
    "        if aplicar_filtros:\n",
    "            df3 = filtra_noticias_nao_relacionadas(df2, empresa)\n",
    "            if len(df3) >0:\n",
    "                df4 = filtra_citacao_relevante(df3, empresa, dfEmpresasListadas )\n",
    "                print(str(dt.datetime.now())  + ' ... novas noticias após filtro citaçoes: ' + str(len(df4)))\n",
    "                df5 = classifica_textos_coletados(df4)\n",
    "        else:\n",
    "            df5 = df2\n",
    "        \n",
    "        if len(df5) >0:\n",
    "            df6 = df5\n",
    "            print(str(dt.datetime.now())  + ' ... novas noticias após filtros: ' + str(len(df6)))\n",
    "            df_atual = pd.read_excel(base_noticias)\n",
    "\n",
    "            # corte de data - se necessario inibir noticias alem de uma data\n",
    "            #df6 = df6[df6.data_publicacao.dt.date < dt.date(2023, 3, 1)]\n",
    "\n",
    "            df = pd.concat([df_atual,df6]).drop_duplicates(ignore_index=True)\n",
    "            df = df.drop_duplicates(['titulo','empresa','fonte', 'texto_completo'], keep='first')\n",
    "            df.to_excel(base_noticias, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfedf3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6788826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd28dae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
